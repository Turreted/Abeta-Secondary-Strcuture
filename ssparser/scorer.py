import pandas as pd
import numpy as np
import os
import pickle

from .stride import parse_with_stride
from .ssparser import parse_ss_freq
from .constants import *
from .utils import get_full_runs
from .utils import get_all_pdb

"""
Scoring algorithm for ABeta-chains generated by AlphaFold

1. Generates a strcuture template based on ABeta monomers in fibrils or complexes
that are taken from the PDB. The files in the database are specified by DATABASE_DIR.
This template contains the frequency of each secondary structure at each position 
(ie the number of times the ith residue was observed to have that secondary strcuture
divided by the total number of chain)

2. Selects 'target residues' which are residues which frequentley have secondary 
strcutures of a specific type

3. For each result generated by AlphaFold, iterate over each target residue and
see if it matches the template. If it does, add the frequency of the secondary
structure in the template to the overall score.

4. Scale the final score by dividing it by the sum of the frequencies at each
position for each chain, thus scaling each residue by the frequency in the 
template.
"""

def generate_score_table(
    alphafold_dir,
    output_dir,
    beta_threshold=0.3,
    turn_threshold=0.2,
    multimer=False,
    relaxed=True,
):

    template_dict = parse_ss_freq(os.listdir(DATASET_DIR))
    beta_template = template_dict["Beta"]
    turn_template = template_dict["Turn"]

    # select all residue indices where the frequency of secondary strcuture is above a threshold
    target_beta_residues_1 = [
        ri for ri, freq in enumerate(beta_template) if freq > beta_threshold and ri < 25
    ]
    target_beta_residues_2 = [
        ri
        for ri, freq in enumerate(beta_template)
        if freq > beta_threshold and ri >= 25
    ]
    target_turn_residues = [
        ri for ri, freq in enumerate(turn_template) if freq > turn_threshold
    ]

    print(
        f"Beta-Strand 1 target residues (threshold of {beta_threshold*100}%): {target_beta_residues_1}"
    )
    print(
        f"Beta-Strand 2 target residues (threshold of {beta_threshold*100}%): {target_beta_residues_2}"
    )
    print(
        f"Turn target residues (threshold of {turn_threshold*100}%):          {target_turn_residues}"
    )

    res = pd.DataFrame(
        columns=[
            "Filename",
            "Beta 1 Score",
            "Turn Score",
            "Beta 2 Score",
            "Plddt",
            "Plddt Target",
        ]
    )

    for sname, mname in get_full_runs(
        alphafold_dir, multimer=multimer, relaxed=relaxed
    ):
        full_struct_path = os.path.join(alphafold_dir, sname)
        full_metadata_path = os.path.join(alphafold_dir, mname)

        struct = parse_with_stride(full_struct_path)

        chain_names = set(struct["Chain"])
        chain_count = len(chain_names)
        beta_score_1 = 0
        beta_score_2 = 0
        turn_score = 0

        for cname in chain_names:
            chain = struct.loc[struct["Chain"] == cname]

            for res_index in range(ABETA_LONG_RESIDUE_COUNT):
                resid = res_index + 1
                residue_data = chain.loc[chain["PDB ResID"] == resid]

                if not residue_data.empty:
                    res_struct_code = list(residue_data["SS Code"])[0]

                    if (
                        res_struct_code in ["B", "b", "E"]
                        and res_index in target_beta_residues_1
                    ):
                        beta_score_1 += beta_template[res_index]

                    if (
                        res_struct_code in ["B", "b", "E"]
                        and res_index in target_beta_residues_2
                    ):
                        beta_score_2 += beta_template[res_index]

                    elif res_struct_code in ["T"] and res_index in target_turn_residues:
                        turn_score += turn_template[res_index]

        # extract AlphaFold score
        mf = open(full_metadata_path, "rb")
        pf = pickle.load(mf)
        plddt_scores = pf["plddt"]
        target_residues = (
            set(target_beta_residues_1)
            .union(target_turn_residues)
            .union(target_beta_residues_2)
        )
        af_score = np.mean([plddt_scores[i] for i in target_residues])

        # take sum of all frequencies so we can divide by then and get scaled result
        beta_sum = sum(
            [
                beta_template[ri]
                for ri in target_beta_residues_1 + target_beta_residues_2
            ]
        )
        turn_sum = sum([turn_template[ri] for ri in target_turn_residues])

        res.loc[len(res.index)] = [
            os.path.basename(sname),
            round(beta_score_1 / (beta_sum * chain_count), 3),
            round(turn_score / (turn_sum * chain_count), 3),
            round(beta_score_2 / (beta_sum * chain_count), 3),
            round(np.mean(plddt_scores), 3),
            round(af_score, 3),
        ]

    res = res.sort_values(by=["Plddt"], ascending=False)
    res.to_csv(os.path.join(output_dir, "table.csv"))


def generate_raw_pdb_score(
    alphafold_dir,
    output_dir,
    beta_threshold=0.3,
    turn_threshold=0.2,
):
    template_dict = parse_ss_freq(os.listdir(DATASET_DIR))
    beta_template = template_dict["Beta"]
    turn_template = template_dict["Turn"]

    # select all residue indices where the frequency of secondary strcuture is above a threshold
    target_beta_residues_1 = [
        ri for ri, freq in enumerate(beta_template) if freq > beta_threshold and ri < 25
    ]
    target_beta_residues_2 = [
        ri
        for ri, freq in enumerate(beta_template)
        if freq > beta_threshold and ri >= 25
    ]
    target_turn_residues = [
        ri for ri, freq in enumerate(turn_template) if freq > turn_threshold
    ]

    print(
        f"Beta-Strand 1 target residues (threshold of {beta_threshold*100}%): {target_beta_residues_1}"
    )
    print(
        f"Beta-Strand 2 target residues (threshold of {beta_threshold*100}%): {target_beta_residues_2}"
    )
    print(
        f"Turn target residues (threshold of {turn_threshold*100}%):          {target_turn_residues}"
    )

    res = pd.DataFrame(
        columns=[
            "Filename",
            "Beta 1 Score",
            "Turn Score",
            "Beta 2 Score",
        ]
    )

    for sname in get_all_pdb(alphafold_dir):
        full_struct_path = os.path.join(alphafold_dir, sname)
        struct = parse_with_stride(full_struct_path)

        chain_names = set(struct["Chain"])
        chain_count = len(chain_names)
        beta_score_1 = 0
        beta_score_2 = 0
        turn_score = 0

        for cname in chain_names:
            chain = struct.loc[struct["Chain"] == cname]

            for res_index in range(ABETA_LONG_RESIDUE_COUNT):
                resid = res_index + 1
                residue_data = chain.loc[chain["PDB ResID"] == resid]

                if not residue_data.empty:
                    res_struct_code = list(residue_data["SS Code"])[0]

                    if (
                        res_struct_code in ["B", "b", "E"]
                        and res_index in target_beta_residues_1
                    ):
                        beta_score_1 += beta_template[res_index]

                    if (
                        res_struct_code in ["B", "b", "E"]
                        and res_index in target_beta_residues_2
                    ):
                        beta_score_2 += beta_template[res_index]

                    elif res_struct_code in ["T"] and res_index in target_turn_residues:
                        turn_score += turn_template[res_index]

        # take sum of all frequencies so we can divide by then and get scaled result
        beta_sum = sum(
            [
                beta_template[ri]
                for ri in target_beta_residues_1 + target_beta_residues_2
            ]
        )
        turn_sum = sum([turn_template[ri] for ri in target_turn_residues])

        res.loc[len(res.index)] = [
            os.path.basename(sname),
            round(beta_score_1 / (beta_sum * chain_count), 3),
            round(turn_score / (turn_sum * chain_count), 3),
            round(beta_score_2 / (beta_sum * chain_count), 3),
        ]

    res.to_csv(os.path.join(output_dir, "table.csv"))
